{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n# Set to check and allow GPU\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\nos.environ['SM_FRAMEWORK'] = 'tf.keras'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n# Install required libs\n\n## Segmentation model training\n!export SM_FRAMEWORK=tf.keras\n\n### please update Albumentations to version>=0.3.0 for `Lambda` transform support\n!pip install -U albumentations>=0.3.0 --user \n!pip install -U --pre segmentation-models --user","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/panda-image-and-cmapped-mask-data/train_images/'\nMASK_DIR = '/kaggle/input/panda-image-and-cmapped-mask-data/train_label_masks/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data loader and utility functions\n# helper function for data visualization\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()\n    \n# helper function for data visualization    \ndef denormalize(x):\n    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n    x_max = np.percentile(x, 98)\n    x_min = np.percentile(x, 2)    \n    x = (x - x_min) / (x_max - x_min)\n    x = x.clip(0, 1)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# classes for data loading and preprocessing\nclass Dataset:\n    \"\"\"Panda Dataset. Read images, apply augmentation and preprocessing transformations.\n    \n    Args:\n        images_dir (str): path to images folder\n        masks_dir (str): path to segmentation masks folder\n        class_values (list): values of classes to extract from segmentation mask\n        augmentation (albumentations.Compose): data transfromation pipeline \n            (e.g. flip, scale, etc.)\n        preprocessing (albumentations.Compose): data preprocessing \n            (e.g. noralization, shape manipulation, etc.)\n    \n    \"\"\"\n    \n    # Radboud images: Prostate glands are individually labelled, valid values are:\n    # 0 : background (non-tissue or unknown)\n    # 1 : stroma (connective tissues, non-epithelium tissue)\n    # 2 : healthy (benign) epithelium\n    # 3 : cancerous epithelium (Gleason 3)\n    # 4 : cancerous epithelium (Gleason 4)\n    # 5  :cancerous epithelium (Gleason 5)\n    CLASSES = ['background', 'stroma', 'healthy', 'gleason3', 'gleason4', 'gleason5']\n    \n    def __init__(\n            self, \n            images_dir, \n            masks_dir, \n            classes=None, \n            augmentation=None, \n            preprocessing=None,\n    ):\n        self.ids = os.listdir(images_dir)\n        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n        \n        # convert str names to class values on masks\n        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n        \n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n           \n    def __getitem__(self, i):\n        \n        # read data\n        image = cv2.imread(self.images_fps[i])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.masks_fps[i], 0)\n        \n        # extract certain classes from mask (e.g. background)\n        masks = [(mask == v) for v in self.class_values]\n        mask = np.stack(masks, axis=-1).astype('float')\n        \n        # add background if mask is not binary\n        if mask.shape[-1] != 1:\n            background = 1 - mask.sum(axis=-1, keepdims=True)\n            mask = np.concatenate((mask, background), axis=-1)\n        \n        # apply augmentations\n        if self.augmentation:\n            sample = self.augmentation(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n        \n        # apply preprocessing\n        if self.preprocessing:\n            sample = self.preprocessing(image=image, mask=mask)\n            image, mask = sample['image'], sample['mask']\n            \n        return image, mask\n        \n    def __len__(self):\n        return len(self.ids)\n       \nclass Dataloder(keras.utils.Sequence):\n    \"\"\"Load data from dataset and form batches\n    \n    Args:\n        dataset: instance of Dataset class for image loading and preprocessing.\n        batch_size: Integet number of images in batch.\n        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n    \"\"\"\n    \n    def __init__(self, dataset, batch_size=1, shuffle=False):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(dataset))\n\n        self.on_epoch_end()\n\n    def __getitem__(self, i):\n        \n        # collect batch data\n        start = i * self.batch_size\n        stop = (i + 1) * self.batch_size\n        data = []\n        for j in range(start, stop):\n            data.append(self.dataset[j])\n        \n        # transpose list of lists\n        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n        \n        #return batch\n        # newer version of tf/keras want batch to be in tuple rather than list\n        # Ref. https://github.com/qubvel/segmentation_models/issues/412\n        return tuple(batch)\n    \n    def __len__(self):\n        \"\"\"Denotes the number of batches per epoch\"\"\"\n        return len(self.indexes) // self.batch_size\n    \n    def on_epoch_end(self):\n        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n        if self.shuffle:\n            self.indexes = np.random.permutation(self.indexes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_dir = os.path.join(DATA_DIR, 'train_images')\ny_train_dir = os.path.join(MASK_DIR, 'train_label_masks')\n\nx_valid_dir = os.path.join(DATA_DIR, 'val')\ny_valid_dir = os.path.join(DATA_DIR, 'valannot')\n\nx_test_dir = os.path.join(DATA_DIR, 'test')\ny_test_dir = os.path.join(DATA_DIR, 'testannot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets look at data we have\ndataset = Dataset(x_train_dir,\n                  y_train_dir,\n                  classes=['background', 'stroma', 'healthy', 'gleason3', 'gleason4', 'gleason5'])\n\nimage, mask = dataset[5] # get some sample\nvisualize(\n    image=image, \n    stroma_mask=mask[..., 0].squeeze(),\n    healthy_mask=mask[..., 1].squeeze(),\n    gleason3_mask=mask[..., 2].squeeze(),\n    gleason4_mask=mask[..., 3].squeeze(),\n    gleason5_mask=mask[..., 4].squeeze()\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Augmentations\n\n\nData augmentation is a powerful technique to increase the amount of your data and prevent model overfitting.\nRefer these articles:\n\nThe Effectiveness of Data Augmentation in Image Classification using Deep Learning\nData Augmentation | How to use Deep Learning when you have Limited Data\nData Augmentation Experimentation\n\nAll this transforms can be easily applied with Albumentations - fast augmentation library. For detailed explanation of image transformations you can look at kaggle salt segmentation exmaple provided by Albumentations authors."},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as A","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_WIDTH = 320\nIMAGE_HEIGHT = 320\n\ndef round_clip_0_1(x, **kwargs):\n    return x.round().clip(0, 1)\n\n# define heavy augmentations\ndef get_training_augmentation():\n    train_transform = [\n        #A.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n        #A.RandomCrop(height=320, width=320, always_apply=True),\n        A.augmentations.geometric.resize.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, always_apply=True)\n    ]\n    return A.Compose(train_transform)\n\n\ndef get_validation_augmentation():\n    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n    test_transform = [\n        #A.PadIfNeeded(384, 480)\n        #A.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n        #A.RandomCrop(height=320, width=320, always_apply=True),\n        #A.augmentations.geometric.resize.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, always_apply=True)\n        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, always_apply=True)\n\n    ]\n    return A.Compose(test_transform)\n\ndef get_preprocessing(preprocessing_fn):\n    \"\"\"Construct preprocessing transform\n    \n    Args:\n        preprocessing_fn (callbale): data normalization function \n            (can be specific for each pretrained neural network)\n    Return:\n        transform: albumentations.Compose\n    \n    \"\"\"\n    \n    _transform = [\n        A.Lambda(image=preprocessing_fn),\n        #A.augmentations.geometric.resize.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, always_apply=True)\n        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, always_apply=True)\n\n\n    ]\n    return A.Compose(_transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Segmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import segmentation_models as sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define some constants\nBACKBONE = 'efficientnetb7'\nBATCH_SIZE = 8\nCLASSES = ['background', 'stroma', 'healthy', 'gleason3', 'gleason4', 'gleason5']\nLR = 0.0001  # Learning rate for the training\nEPOCHS = 15  # Number of epochs\n\npreprocess_input = sm.get_preprocessing(BACKBONE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define network parameters\nn_classes = len(CLASSES)  # multiclass segmentation\nactivation = 'softmax'\n\n#create model\nmodel = sm.Unet(BACKBONE, classes=n_classes, activation=activation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define optomizer\noptim = keras.optimizers.Adam(LR)\n\n# Use binary focal dice loss as the loss optimization metric\ntotal_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n\n# Track IOU Score and F1 score during training.\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n\n# compile keras model with defined optimozer, loss and metrics\nmodel.compile(optim, total_loss, metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset for train images\ntrain_dataset = Dataset(\n    x_train_dir, \n    y_train_dir, \n    classes=CLASSES, \n    #augmentation=get_training_augmentation(),\n    augmentation=None,\n    preprocessing=get_preprocessing(preprocess_input),\n)\n\n# Dataset for validation images\nvalid_dataset = Dataset(\n    x_valid_dir, \n    y_valid_dir, \n    classes=CLASSES, \n    #augmentation=get_validation_augmentation(),\n    augmentation=None,\n    preprocessing=get_preprocessing(preprocess_input),\n)\n\ntrain_dataloader = Dataloder(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nvalid_dataloader = Dataloder(valid_dataset, batch_size=1, shuffle=False)\n\n# check shapes for errors\nassert train_dataloader[0][0].shape == (BATCH_SIZE, IMAGE_WIDTH, IMAGE_HEIGHT, 3)\nassert train_dataloader[0][1].shape == (BATCH_SIZE, IMAGE_WIDTH, IMAGE_HEIGHT, n_classes)\n\n# define callbacks for learning rate scheduling and save model at best checkpoint.\ncallbacks = [\n    keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n    keras.callbacks.ReduceLROnPlateau(),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nhistory = model.fit(\n    train_dataloader, \n    steps_per_epoch=len(train_dataloader), \n    epochs=EPOCHS, \n    callbacks=callbacks, \n    validation_data=valid_dataloader, \n    validation_steps=len(valid_dataloader),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot training & validation iou_score values\nplt.figure(figsize=(30, 5))\nplt.subplot(121)\nplt.plot(history.history['iou_score'])\nplt.plot(history.history['val_iou_score'])\nplt.title('Model iou_score')\nplt.ylabel('iou_score')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(122)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = Dataset(\n    x_test_dir, \n    y_test_dir, \n    classes=CLASSES, \n    augmentation=get_validation_augmentation(),\n    preprocessing=get_preprocessing(preprocess_input),\n)\n\ntest_dataloader = Dataloder(test_dataset, batch_size=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load best weights (from the training epoch)\nmodel.load_weights('best_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(test_dataloader)\n\nprint(\"Loss: {:.5}\".format(scores[0]))\nfor metric, value in zip(metrics, scores[1:]):\n    print(\"mean {}: {:.5}\".format(metric.__name__, value))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization of results on test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 5\nids = np.random.choice(np.arange(len(test_dataset)), size=n)\n\nfor i in ids:\n    \n    image, gt_mask = test_dataset[i]\n    image = np.expand_dims(image, axis=0)\n    pr_mask = model.predict(image)\n    \n    visualize(\n        image=denormalize(image.squeeze()),\n        gt_mask=gt_mask.squeeze(),\n        pr_mask=pr_mask.squeeze(),\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}